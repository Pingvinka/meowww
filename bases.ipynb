{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967101a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"Версия Python:\", os.sys.version)\n",
    "print(\"Версия PyTorch:\", torch.__version__)\n",
    "print(\"CUDA доступна:\", torch.cuda.is_available())\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda323a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c211618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers datasets accelerate sentencepiece\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "\n",
    "MODEL_NAME = \"Vikhrmodels/Vikhr-Gemma-2B-instruct\"  \n",
    "print(\"Модель:\", MODEL_NAME)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b93410",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./data\")  \n",
    "train_llm_path = DATA_DIR / \"train_llm.csv\"\n",
    "test_llm_path = DATA_DIR / \"test_llm.csv\"\n",
    "\n",
    "train_llm = pd.read_csv(train_llm_path)\n",
    "test_llm = pd.read_csv(test_llm_path)\n",
    "\n",
    "print(\"train_llm shape:\", train_llm.shape)\n",
    "print(\"test_llm shape:\", test_llm.shape)\n",
    "train_llm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d69ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_instruction(example):\n",
    "    return f\"\"\"Задача: Классифицируй текст на одну из двух категорий.\n",
    "            Текст: {example['prompt']}\n",
    "\n",
    "            Классифицируй текст как:\n",
    "            - 1 (положительный), если текст относится к положительному классу\n",
    "            - 0 (отрицательный), если текст относится к отрицательному классу\n",
    "\n",
    "            Ответ: {example['response']}\"\"\"\n",
    "\n",
    "train_texts = [build_instruction(row) for _, row in train_llm.iterrows()]\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"text\": train_texts})\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0776411",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./llm_russian_baseline\"\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,          # увеличивай при необходимости\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_steps=50,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "def build_prompt_for_inference(prompt_text: str) -> str:\n",
    "    # Формат должен совпадать с форматом на обучении\n",
    "    return f\"Инструкция: {prompt_text} Ответ:\"\n",
    "\n",
    "def generate_answer(prompt_text: str, max_new_tokens: int = 64) -> str:\n",
    "    input_text = build_prompt_for_inference(prompt_text)\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.8,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    full_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    if \"Ответ:\" in full_text:\n",
    "        answer_part = full_text.split(\"Ответ:\", 1)[1]\n",
    "    else:\n",
    "        answer_part = full_text\n",
    "    return answer_part.strip()\n",
    "\n",
    "\n",
    "test_predictions = []\n",
    "for i, row in test_llm.iterrows():\n",
    "    ans = generate_answer(row[\"prompt\"])\n",
    "    test_predictions.append(ans)\n",
    "    if i < 3:\n",
    "        print(\"PROMPT:\", row[\"prompt\"])\n",
    "        print(\"ANSWER:\", ans)\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "submission_llm = test_llm.copy()\n",
    "submission_llm[\"response\"] = test_predictions\n",
    "\n",
    "submission_llm_path = Path(\"./submission_llm.csv\")\n",
    "submission_llm.to_csv(submission_llm_path, index=False)\n",
    "submission_llm_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9bdac3",
   "metadata": {},
   "source": [
    "#Звук"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df1fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torchaudio\n",
    "    print(\"torchaudio версия:\", torchaudio.__version__)\n",
    "except ImportError as e:\n",
    "    print(\"torchaudio не найден. При необходимости установи или замени на librosa.\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_path = DATA_DIR / \"train_audio.csv\"\n",
    "test_audio_path = DATA_DIR / \"test_audio.csv\"\n",
    "\n",
    "train_audio = pd.read_csv(train_audio_path)\n",
    "test_audio = pd.read_csv(test_audio_path)\n",
    "\n",
    "print(train_audio.head())\n",
    "print(test_audio.head())\n",
    "\n",
    "label2id = {lbl: i for i, lbl in enumerate(sorted(train_audio[\"label\"].unique()))}\n",
    "id2label = {i: lbl for lbl, i in label2id.items()}\n",
    "\n",
    "num_classes = len(label2id)\n",
    "num_classes, label2id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c7f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, df, data_dir: Path, label2id=None, train: bool = True, sample_rate: int = 16000):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.data_dir = data_dir\n",
    "        self.train = train\n",
    "        self.label2id = label2id\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        self.resampler = torchaudio.transforms.Resample(orig_freq=None, new_freq=sample_rate)\n",
    "        self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate,\n",
    "            n_fft=1024,\n",
    "            hop_length=256,\n",
    "            n_mels=64\n",
    "        )\n",
    "        self.ampl2db = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        wav_path = self.data_dir / row[\"path\"]\n",
    "\n",
    "        waveform, sr = torchaudio.load(str(wav_path))\n",
    "        if sr != self.sample_rate:\n",
    "            waveform = self.resampler(waveform)\n",
    "\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        melspec = self.melspec(waveform)  \n",
    "        melspec_db = self.ampl2db(melspec)\n",
    "        melspec_db = (melspec_db - melspec_db.mean()) / (melspec_db.std() + 1e-6)\n",
    "\n",
    "        if self.train and self.label2id is not None:\n",
    "            label = self.label2id[row[\"label\"]]\n",
    "            return melspec_db, label\n",
    "        else:\n",
    "            return melspec_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAudioCNN(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((8, 8))\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81818af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train_audio, test_size=0.2, stratify=train_audio[\"label\"], random_state=42)\n",
    "\n",
    "train_ds = AudioDataset(train_df, DATA_DIR, label2id=label2id, train=True)\n",
    "val_ds = AudioDataset(val_df, DATA_DIR, label2id=label2id, train=True)\n",
    "test_ds = AudioDataset(test_audio, DATA_DIR, label2id=None, train=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "audio_model = SimpleAudioCNN(num_classes=num_classes).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(audio_model.parameters(), lr=1e-3)\n",
    "\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == y).sum().item()\n",
    "        total_count += x.size(0)\n",
    "    return total_loss / total_count, total_correct / total_count\n",
    "\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            total_count += x.size(0)\n",
    "    return total_loss / total_count, total_correct / total_count\n",
    "\n",
    "EPOCHS = 3\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    tr_loss, tr_acc = train_epoch(audio_model, train_loader)\n",
    "    val_loss, val_acc = eval_epoch(audio_model, val_loader)\n",
    "    print(f\"Epoch {epoch}: train_loss={tr_loss:.4f}, train_acc={tr_acc:.4f}, val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e6ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_model.eval()\n",
    "test_preds_ids = []\n",
    "with torch.no_grad():\n",
    "    for x in test_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        logits = audio_model(x)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy().tolist()\n",
    "        test_preds_ids.extend(preds)\n",
    "\n",
    "test_labels = [id2label[i] for i in test_preds_ids]\n",
    "\n",
    "submission_audio = test_audio.copy()\n",
    "submission_audio[\"label\"] = test_labels\n",
    "submission_audio_path = Path(\"./submission_audio.csv\")\n",
    "submission_audio.to_csv(submission_audio_path, index=False)\n",
    "submission_audio_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e3161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rec_path = DATA_DIR / \"train_rec.csv\"\n",
    "test_rec_path = DATA_DIR / \"test_rec.csv\"\n",
    "\n",
    "if train_rec_path.exists() and test_rec_path.exists():\n",
    "    train_rec = pd.read_csv(train_rec_path)\n",
    "    test_rec = pd.read_csv(test_rec_path)\n",
    "\n",
    "    print(train_rec.head())\n",
    "    print(test_rec.head())\n",
    "else:\n",
    "    print(\"Файлы train_rec/test_rec не найдены. Пропусти этот блок или добавь свои файлы.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0bcab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train_rec' in globals():\n",
    "    global_mean = train_rec[\"rating\"].mean()\n",
    "\n",
    "    item_mean = train_rec.groupby(\"item_id\")[\"rating\"].mean()\n",
    "    user_mean = train_rec.groupby(\"user_id\")[\"rating\"].mean()\n",
    "\n",
    "    def predict_baseline(u, i):\n",
    "        if i in item_mean:\n",
    "            return item_mean[i]\n",
    "        elif u in user_mean:\n",
    "            return user_mean[u]\n",
    "        else:\n",
    "            return global_mean\n",
    "\n",
    "    preds = []\n",
    "    for _, row in test_rec.iterrows():\n",
    "        u = row[\"user_id\"]\n",
    "        i = row[\"item_id\"]\n",
    "        preds.append(predict_baseline(u, i))\n",
    "\n",
    "    submission_rec = test_rec.copy()\n",
    "    submission_rec[\"rating\"] = preds\n",
    "    submission_rec_path = Path(\"./submission_rec_baseline.csv\")\n",
    "    submission_rec.to_csv(submission_rec_path, index=False)\n",
    "    submission_rec_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b2fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train_rec' in globals():\n",
    "    # Зашиваем индексацию\n",
    "    unique_users = train_rec[\"user_id\"].unique()\n",
    "    unique_items = train_rec[\"item_id\"].unique()\n",
    "\n",
    "    user2idx = {u: idx for idx, u in enumerate(unique_users)}\n",
    "    item2idx = {i: idx for idx, i in enumerate(unique_items)}\n",
    "\n",
    "    train_rec[\"user_idx\"] = train_rec[\"user_id\"].map(user2idx)\n",
    "    train_rec[\"item_idx\"] = train_rec[\"item_id\"].map(item2idx)\n",
    "\n",
    "    class RecDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, df):\n",
    "            self.user_idx = df[\"user_idx\"].values\n",
    "            self.item_idx = df[\"item_idx\"].values\n",
    "            self.rating = df[\"rating\"].values.astype(\"float32\")\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.rating)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return (\n",
    "                torch.tensor(self.user_idx[idx], dtype=torch.long),\n",
    "                torch.tensor(self.item_idx[idx], dtype=torch.long),\n",
    "                torch.tensor(self.rating[idx], dtype=torch.float32),\n",
    "            )\n",
    "\n",
    "    class MFModel(nn.Module):\n",
    "        def __init__(self, n_users, n_items, n_factors=32):\n",
    "            super().__init__()\n",
    "            self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "            self.item_emb = nn.Embedding(n_items, n_factors)\n",
    "            self.user_bias = nn.Embedding(n_users, 1)\n",
    "            self.item_bias = nn.Embedding(n_items, 1)\n",
    "            self.global_bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        def forward(self, user_idx, item_idx):\n",
    "            u = self.user_emb(user_idx)\n",
    "            v = self.item_emb(item_idx)\n",
    "            dot = (u * v).sum(dim=1)\n",
    "            bu = self.user_bias(user_idx).squeeze(-1)\n",
    "            bi = self.item_bias(item_idx).squeeze(-1)\n",
    "            return dot + bu + bi + self.global_bias\n",
    "\n",
    "    rec_ds = RecDataset(train_rec)\n",
    "    rec_loader = torch.utils.data.DataLoader(rec_ds, batch_size=1024, shuffle=True)\n",
    "\n",
    "    n_users = len(unique_users)\n",
    "    n_items = len(unique_items)\n",
    "    mf_model = MFModel(n_users, n_items).to(DEVICE)\n",
    "    mf_optimizer = torch.optim.Adam(mf_model.parameters(), lr=1e-2)\n",
    "    mf_criterion = nn.MSELoss()\n",
    "\n",
    "    EPOCHS_MF = 5  # можно изменить\n",
    "    for epoch in range(1, EPOCHS_MF + 1):\n",
    "        mf_model.train()\n",
    "        total_loss = 0\n",
    "        total_count = 0\n",
    "        for u_idx, i_idx, r in rec_loader:\n",
    "            u_idx = u_idx.to(DEVICE)\n",
    "            i_idx = i_idx.to(DEVICE)\n",
    "            r = r.to(DEVICE)\n",
    "\n",
    "            mf_optimizer.zero_grad()\n",
    "            pred = mf_model(u_idx, i_idx)\n",
    "            loss = mf_criterion(pred, r)\n",
    "            loss.backward()\n",
    "            mf_optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * r.size(0)\n",
    "            total_count += r.size(0)\n",
    "        print(f\"[MF] Epoch {epoch}: train_loss={total_loss / total_count:.4f}\")\n",
    "\n",
    "    # Предсказания для теста (если item/user не в train, fallback на global_mean)\n",
    "    preds_mf = []\n",
    "    mf_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, row in test_rec.iterrows():\n",
    "            u = row[\"user_id\"]\n",
    "            i = row[\"item_id\"]\n",
    "            if (u in user2idx) and (i in item2idx):\n",
    "                u_idx = torch.tensor([user2idx[u]], dtype=torch.long).to(DEVICE)\n",
    "                i_idx = torch.tensor([item2idx[i]], dtype=torch.long).to(DEVICE)\n",
    "                r_hat = mf_model(u_idx, i_idx).item()\n",
    "            else:\n",
    "                r_hat = global_mean\n",
    "            preds_mf.append(r_hat)\n",
    "\n",
    "    submission_rec_mf = test_rec.copy()\n",
    "    submission_rec_mf[\"rating\"] = preds_mf\n",
    "    submission_rec_mf_path = Path(\"./submission_rec_mf.csv\")\n",
    "    submission_rec_mf.to_csv(submission_rec_mf_path, index=False)\n",
    "    submission_rec_mf_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
